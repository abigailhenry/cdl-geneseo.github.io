## Ways to evaluate online teaching

As a result of the coronavirus pandemic, many more faculty than in the past are teaching online. Not surprisingly, then, a question I’ve been asked repeatedly of late is this: *What’s the best way for department chairs, deans, and personnel committees to evaluate the quality of online teaching and support their colleagues’ professional development in this area?*

Procedures and standards for peer review of faculty are properly a matter for shared governance. At some point it will fall to the college senate to approve guidelines for “observing” online instruction similar to [those it adopted in 2006 for on-ground instruction](https://wiki.geneseo.edu/download/attachments/109184288/Classroom%20Observation%20Procedures%20and%20Criteria.pdf?version=1&modificationDate=1479164407556&api=v2), possibly together with some online-specific modifications to the personnel evaluation forms for tenured/tenure-track and adjunct faculty. But because schools and departments need help with this question right now, I put down some thoughts and shared them with the CDL [faculty affiliates](https://www.geneseo.edu/cdl/faculty-affiliates), [student affiliates](https://www.geneseo.edu/cdl/student-affiliates), [associates](https://www.geneseo.edu/cdl/cdl-associates), and [leadership team](https://www.geneseo.edu/cdl/leadership), as well as the Academic Experience Planning Team convened last spring by Provost Robertson to develop recommendations for the transition to remote learning. I got a lot of terrific feedback, especially in the faculty affilites' meeting on September 9. 

What follows isn't a group document but my best advice, informed by the range of perspectives I heard in that feedback. As you might expect, the perspectives didn't line up neatly, but with perhaps one exception there was no major point of disagreement.

For those who like their conclusions first, here's the short version of my advice:

- Be guided by best practices for evaluating online instruction, but adapt them to present circumstances: faculty workloads and pressures right now call for a streamlined approach that respects everyone's limited time as well as the psychological strains on colleagues under review, especially those without tenure.
- In establishing a temporary procedure for your school or department, consider the difference between physical and online spaces when it comes to both faculty's and students' sense of privacy and safety. Various online equivalents to the conventional "friendly classroom visit" may leave some people feeling uncomfortably exposed or surveilled and may cause some students to  feel as though their trust has been violated.
- Whatever approach your school or department takes, make sure everyone fully understands the why and how of it and that everyone follows it consistently. 

# Two questions, not one

For Geneseo right now the question of how best to evaluate online teaching is really two questions. First, in the abstract, what constitutes best practice for peer evaluation and mentorship in this area? But second, what’s a fair, reasonable, and practicable approach to assessing and mentoring colleagues under our present unusual circumstances, where many instructors, evaluators, and students are operating in unfamiliar territory, with new instructional modalities and with tools they may be trying for the first time?

One thing I think we can say in answer to both questions: When evaluating physically present teaching, it’s common to attach the highest importance to the way a colleague interacts with students in the classroom. The colleague’s portfolio of course materials — syllabi, assignments, handouts, websites, and the like — are important, too, but usually regarded as a less reliable measure of effectiveness. In evaluating online teaching, however, we’re forced to think differently about the relative usefulness of these two measures. Asynchronous online courses don’t have a “classroom” to visit. Meanwhile, good course design and engaging asynchronous interaction are so fundamental to successful online instruction that it makes more sense to measure a faculty member’s effectiveness by examining their course structure and content than by looking for ways to reproduce traditional in-class observation.

A number of standards and rubrics are available to assess online course design. [Quality Matters](https://www.qualitymatters.org/), a nonprofit organization that grew out of a higher-education consortium in Maryland, provides an [adaptable, standards-driven review process](https://www.qualitymatters.org/why-quality-matters/process) that institutions can use to assess the quality of their online offerings. SUNY has developed its own instrument for developing and assessing online courses, the Online Course Quality Review Rubric: [OSCQR](https://oscqr.suny.edu/) for short. These tools have the advantage of being backed by extensive research on effective online course design. They're thorough and detailed: OSCQR, for example, comprises 50 standards arranged under six dimensions of online course architecture and implementation: Overview and Information, Technology and Tools, Design and Layout, Content and Activities, Interaction, Assessment and Feedback. However, the tools are intended as frameworks for the full online course evaluation process, from development through review to improvement. They presume an instructor who's deliberately chosen to teach online and to build courses informed by the tools' design principles. They also presume evaluators thoroughly familiar with those principles. *Needless to say, that’s not the situation we’re in right now.*

Under present circumstances, a better approach to evaluating instructors' courses would be to rate them against just a few, high-level principles of effective practice. One starting point might be Geneseo’s [Course Readiness Checklist](https://wp.geneseo.edu/etc/wp-content/uploads/sites/13/2020/04/course-readiness-checklist-v3.pdf), the greatly streamlined version of OSCQR developed by CDL Assistant Director for Online Learning Laurie Fox and her team of instructional designers in CIT. Departments could adapt it to fit distinctive aspects of their disciplines or cultures. At [Penn State College of Earth and Mineral Sciences](https://facdev.e-education.psu.edu/evaluate-revise/peerreviewonline), Ann Taylor, a member of the Dutton E-Education Institute, began at a still higher conceptual level in developing her Creative Commons-licensed [Peer-Review Guide for Online Courses](https://facdev.e-education.psu.edu/sites/default/files/PeerReview_OnlineCourses_PSU_Guide_13June2017.pdf). Taylor’s guide is based on the “Seven Principles for Good Practice in Undergraduate Education” distilled from research on student learning by Arthur Chickering and Zelda Gamson in their [influential 1987 article](https://files.eric.ed.gov/fulltext/ED282491.pdf) of that name. Because these principles apply to every course modality, from fully in-person to varieties of hybrid to fully online, they’re likely to be recognized and understood by the largest number of faculty.

The best undergraduate teaching, Chickering and Gamson argued,

- Encourages contacts between students and faculty
- Develops reciprocity and cooperation among students
- Uses active learning techniques
- Gives prompt feedback
- Emphasizes time on task
- Communicates high expectations
- Respects diverse talents and ways of learning

Taylor’s peer-review guide indicates where reviewers could look within an online course to see how the course measures up against these principles. Geneseo deans, department chairs, and personnel committees might consider adapting Taylor’s guide to come up with a form and a process that reflects the particular ways in which their respective disciplines realize the seven principles, weaves in additional high-level institutional values such as equity and inclusion, and respects the constraints of time and experience under which we’re all operating right now.

Whatever approach is taken*,* the important thing is to *make sure the process and the standards it employs are transparent to faculty under review and followed consistently by reviewers.* Taylor’s guide spells out how Penn State instructors should initiate and reviewers carry out their process. Academic departments at Geneseo should do the same. However it works, the process will require instructors to give one or more peers some level of access to their online courses in Canvas. CIT can help instructors provide appropriate access in a way that protects the privacy of students in the course.

At Geneseo, faculty undergoing personnel review typically prepare a self-reflective statement together with evidence of their teaching effectiveness that includes course materials (syllabi, handouts, assignments, etc.) and examples of student work. In writing reflectively about their online teaching, faculty might describe how they see the design and content of their online courses meeting the discipline-specific version of standards such as those described above. Additionally, as evidence of growth, they might explain how they’ve changed their online teaching in light of previous experience. And they might illustrate their effectiveness by including examples of student engagement such as de-identified excerpts from discussion forums.

Earlier, I pointed out that in asynchronous online courses, there’s no classroom to visit. What about synchronous online courses, where it would be possible, in principle, for a colleague to “drop in” on a Zoom lecture or discussion to get a feel for an instructor’s pedagogical style?

It’s not hard to imagine a future — hopefully a pandemic-free one — where videoconferencing has become so commonplace and the technology has made it so intuitive that we can all “read” people’s conferencing interactions as easily as we do their in-person ones, a future where we can confidently assess the online equivalent of how well a colleague “uses the board” or facilitates a sense of community in a physical classroom. (How nimble is their screen-sharing? How effectively do they use breakout rooms?) But until we get there, and considering that many faculty are working hard to gain fluency with a raft of new tools and methods for live online engagement, sitting in on a colleague’s Zoom classroom to watch in real time will likely reveal little about pedagogical effectiveness even as it generates a level of anxiety bordering on cruelty. The CDL strongly recommends against using live visitation as a replacement for the type of review described above, even in courses that rely heavily on synchronous meetings, since even these courses ought to show evidence in Canvas of design and content answering to the college’s and department’s principles for quality instruction. Under present circumstances, we recommend against live visitation even as a supplement to looking inside a colleague’s Canvas courses, unless it’s at the colleague’s insistence. Ditto for review of recorded synchronous meetings.

Finally, it’s worth considering what future role student opinion might play in evaluating online teaching. At Geneseo, our process for evaluating physically present teaching has for many years included student opinion through the SOFI survey. The college senate is currently reviewing this practice with an eye toward turning a radically revised SOFI into an instrument for formative assessment that would no longer play a role in personnel evaluation. Eventually, it may make sense to have a dedicated instrument for evaluating online teaching that would serve the same developmental purpose and would be similarly excluded from use in personnel decisions. It might ask the kinds of questions that could help a faculty member gauge how well they succeeded in, for example, establishing a personal presence, making students feel welcome and connected, tying activities and assignments to course learning outcomes, and communicating expectations and feedback effectively.

Whether and how student opinion should play a role in improving online teaching and learning at Geneseo is another matter to be determined through shared governance. To repeat, what you’ve been reading here is advice, not policy. Hopefully it’s helpful advice at a moment when there’s not yet settled policy to guide us.
