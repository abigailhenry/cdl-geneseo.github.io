# Do *you* know where your data goes?

At the beginning of the Fall 2020 semester, professors shared concerns about a new phenomenon known as "Zoom-bombing," wherein a hacker or otherwise uninvited user disrupts a Zoom call. Digital disruptions like these are far from ideal, but can be managed; perhaps the more sinister component of Zoom-bombing follows from the notion of an outsider becoming privy to our private, intellectual property, without our awareness or consent. However, Zoom is not the only area where this breach of privacy occurs. In Zoom, the "Zoom-bomber" poses a visible threat, but in Learning Management Systems like Canvas, the inner-workings of Big Data and [learning analytics technology](https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-019-0155-0) threaten our autonomy nigh-on invisibly. 

"Big Data" and higher-education have aligned in their pursuit of student data, aiming to "mine for insights into student behaviors, learning processes, and institutional practices using learning analytics technology" (Jones 2019). Learning analytics technology, or data-harvesting systems, are applied in the context of LMSs like Canvas. At a glance, the means of data collection in higher ed seem justified by their proposed end-goal of institutional improvement. It's not particularly surprising that student and faculty data is being continuously gathered by Canvas, like Google and other platforms we regularly interact with. Canvas outlines the type of data they collect in their privacy policy, which seems innocuous until the final line: 
> To make our Site, Apps, and Services more useful to you, our servers (which may be hosted by a third party service provider) collect information from you, including browser type, operating system, Internet Protocol (IP) address...domain name, and/or a date/time stamp for your visit. We also use cookies and web beacons (as described below) and navigational data like Uniform Resource Locators (URL) to gather information regarding the date and time of your visit and the solutions and information for which you searched and which you viewed. Like most Internet services, we automatically gather this data and store it in log files each time you visit our Site, use our Apps, or access your account on our network. **We may link this automatically-collected data to personally identifiable information.** (Instructure 2018)

Can the data LMSs collect truly reflect who we are as individuals? Learning analytics strive to compose a "data-double" of the  individual, a move that flattens our human complexity: "in doing so, individuals are taken from a corporeal whole and transformed into binary code as ‘data doubles’ with the purpose of changing ‘the body into pure information, such that it can be rendered more mobile and comparable.' The problem is that the data double fails to be a ‘comprehensive or representative’ reflection of human life, yet powerful actors use it to influence a person’s behavior" (Jones 2019). Ascribing identity based on data collected without our awareness or consent seems unethical to me, regardless of its ends. For one, the data collected by LMSs may yield an inaccurate profile that "follows" us from one institution to another, impacting our future education and career opportunities, especially if we use (and are used) by LMSs from an early age. This is especially concerning right now, when LMSs are being used in the K-12 setting more than ever before. More generally, "students may rightfully be worried that the data and insights mined from [Canvas] will become a part of their permanent educational record and lead to decontextualized decision making" (Jones 2019). We have limited control over the algorithmic calculations that prescribe us identities on these platforms. We have even less control over where this information ends up. Recently, Canvas was purchased by a private investment equity firm for two billion dollars, rendering our data more vulnerable than ever: "With no federal privacy laws governing student data brokers, student data can be collected, sold, and bought without any apparent legal protections from widespread exploitation" (Mariachi and Quill 2020). 

Since the outbreak of the novel coronavirus last spring, we have become increasingly dependent on Canvas as a learning tool, and rejecting its widespread use is simply not a viable option. Despite a seeming lack of control over our own data within this system, we shouldn't feel powerless. In fact, now that this information is gradually becoming more transparent, we should feel empowered to make informed decisions based on our new awareness. Part of this awareness is recognizing and questioning the current lack of transparency concerning information practices in higher education. For starters, many students are not aware of the extent by which their data is gathered, not to mention to what end the institution is gathering this information. Should higher education institutions be obligated to inform students of their data collection policies? Following from this, should students be extended the ability to consent to data collection in LMSs? To what degree should they have control over how and what data is analyzed? To what extent should they be allowed to express their personal privacy preferences? Might these considerations undermine the (opaque) goals of learning analytics, which brings us to wonder: are these goals in our best interest, anyway? 

Moving forward, we must remain vigilant of the invisible threat upon the privacy of our data and identity posed by learning analytics systems, and prioritize seeking transparency in their algorithms. Improvements to the LMS model are needed if we expect it to beneficially serve us in higher education; otherwise, we risk being coerced by the learning management system. Chief among these improvements would be informing students and faculty how and why their data is being collected, and then offering them the ability to consent to this collection, or otherwise decide how their data will be analyzed.  

References
---
Jones, K.M.L. Learning analytics and higher education: a proposed model for establishing informed consent mechanisms to promote student privacy and autonomy. Int J Educ Technol High Educ 16, 24 (2019). https://doi.org/10.1186/s41239-019-0155-0

Roxana Marachi & Lawrence Quill (2020) The case of Canvas: Longitudinal datafication through learning management systems, Teaching in Higher Education, 25:4, 418-434

Something blah blah blah yada yada yada 