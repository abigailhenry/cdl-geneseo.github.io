---
layout: post
title: Awareness and agency: do you know where your data goes?
author: Emma Raupp
---

Are you surprised when a pair of shoes you were looking at online pops up in an ad on Facebook? Probably not. It's 2020: most of us are aware, to varying degrees, that websites and other platforms we interact with track our data. It's the new normal; we may not be fully aware of the scope and means of data-mining, but we make up for this with a suspended sense of wariness surrounding our actions on the Internet. Naturally, we proceed with caution in arenas we do not have a clear perception or understanding of, like the overlap between Big Data and the Internet. Being aware of where your data is going (and why) is key to maintaining a sense of autonomy over your digital self. It's especially important that students recognize their right to such an awareness when it concerns data gathered by Higher Education institutions. In Learning Management Systems like Canvas, [learning analytics technology] (https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-019-0155-0) is implemented to accrue more information about students and their educational habits in order to improve the institution. One unintentional result of the LMS and learning analytics model is that students' data is being collected  without their awareness or consent, with largely uncertain consequences. 

"Big Data" and higher-education have aligned in their pursuit of student data, aiming to "mine for insights into student behaviors, learning processes, and institutional practices using learning analytics technology" (Jones 2019). Learning analytics technology, or data-harvesting systems, are applied in the context of LMSs like Canvas. At a glance, the means of data collection in Higher Ed seem justified by their proposed end-goal of institutional improvement. It's not particularly surprising that student and faculty data is being continuously gathered by Canvas, like Google and other platforms we regularly interact with. Canvas outlines the type of data they collect in their privacy policy, which seems innocuous until the final line: 
> To make our Site, Apps, and Services more useful to you, our servers (which may be hosted by a third party service provider) collect information from you, including browser type, operating system, Internet Protocol (IP) address...domain name, and/or a date/time stamp for your visit. We also use cookies and web beacons (as described below) and navigational data like Uniform Resource Locators (URL) to gather information regarding the date and time of your visit and the solutions and information for which you searched and which you viewed. Like most Internet services, we automatically gather this data and store it in log files each time you visit our Site, use our Apps, or access your account on our network. **We may link this automatically-collected data to personally identifiable information.** (Instructure 2018)

Can the data LMSs collect truly reflect who we are as individuals? Learning analytics strive to compose a "data-double" of the  individual, a move that flattens our human complexity: "in doing so, individuals are taken from a corporeal whole and transformed into binary code as ‘data doubles’ with the purpose of changing ‘the body into pure information, such that it can be rendered more mobile and comparable.' The problem is that the data double fails to be a ‘comprehensive or representative’ reflection of human life, yet powerful actors use it to influence a person’s behavior" (Jones 2019). Ascribing an identity based on data collected without the individual's awareness or consent seems unethical, regardless of its ends. For one, the data collected by LMSs may yield an inaccurate profile that "follows" students from one institution to another, impacting their future education and career opportunities, especially if they use (and are used) by LMSs from an early age. This is especially concerning right now, when LMSs are being used in the K-12 setting more than ever before. More generally, "students may rightfully be worried that the data and insights mined from [Canvas] will become a part of their permanent educational record and lead to decontextualized decision making" (Jones 2019). We have limited control over the algorithmic calculations that prescribe us identities on these platforms. We have even less control over where this information ends up. Recently, Canvas was purchased by a private investment equity firm for two billion dollars, rendering our data more vulnerable than ever: "With no federal privacy laws governing student data brokers, student data can be collected, sold, and bought without any apparent legal protections from widespread exploitation" (Mariachi and Quill 2020). 

Since the outbreak of the novel coronavirus last spring, we are dependent on Canvas as a learning tool more than ever before, and rejecting its widespread use is simply not a viable option. Despite a seeming lack of control over our own data within this system, we shouldn't feel powerless. In fact, now that this information is gradually becoming more transparent, we should feel empowered to make informed decisions based on our new awareness. Part of this awareness is recognizing and questioning the current opacity concerning information practices in higher education. To start, many students are not aware of the extent to which their data is gathered, not to mention to what end the institution is gathering this information. Since it's their data being collected, students retain the right to question institutional data collection policies, and demand a clearer communication of these policies. Further, students should exercise their individual agency by holding the hard line on questions concerning consent and control. If students are not extended the ability to consent to data analysis in the Learning Management System, it's up to them to champion personal privacy preferences and demand answers. What data is being collected, and where is it going? If the system was created with improvement in mind, why is consent absent from the model? Students must remember that their voice, both as individuals and as a collective, matters, and is a powerful force for addressing institutional oversights. 

Moving forward, we should strive for a greater awareness of the learning analytics system, rather than a greater wariness. Improvements to the LMS model are needed if we expect it to beneficially serve us in higher education; otherwise, we risk being coerced by the learning management system. Chief among these improvements would be informing students and faculty how and why their data is being collected, and then offering them the ability to consent to this collection, or otherwise decide how their data will be analyzed. The push toward transparency in institutional data-tracking habits begins when students realize that it is their right and responsibility to be aware of where their data goes, both online and on an educational platform like Canvas. It's our right as students to address the policies that unfairly affect us, but it's also our duty to be agents for ourselves and our information when our autonomy is threatened. It's up to us to seek and spread awareness, upholding student agency to question the powers that be, in turn creating a better future for ourselves and the students to come. 

References
---
Jones, K.M.L. Learning analytics and higher education: a proposed model for establishing informed consent mechanisms to promote student privacy and autonomy. Int J Educ Technol High Educ 16, 24 (2019). https://doi.org/10.1186/s41239-019-0155-0

Roxana Marachi & Lawrence Quill (2020) The case of Canvas: Longitudinal datafication through learning management systems, Teaching in Higher Education, 25:4, 418-434
